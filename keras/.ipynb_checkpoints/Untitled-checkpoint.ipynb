{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from CustomCallbacks import *\n",
    "import pickle\n",
    "from models import mini_XCEPTION, tiny_XCEPTION\n",
    "from data import load_emotion_data, split_data\n",
    "import datetime\n",
    "import os\n",
    "import copy\n",
    "from GenericNetworkBuilder import *\n",
    "import glob\n",
    "import math\n",
    "import random\n",
    "import cv2\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "\n",
    "def SetUpDataGenerators(train_path, val_path, batch_size, w, h):\n",
    "    # batch_size = 16\n",
    "\n",
    "    training_datagen =ImageDataGenerator(featurewise_center=False,\n",
    "                                    featurewise_std_normalization=False,\n",
    "                                    rotation_range=10,\n",
    "                                    width_shift_range=0.1,\n",
    "                                    height_shift_range=0.1,\n",
    "                                    zoom_range=.1,\n",
    "                                    horizontal_flip=True)\n",
    "\n",
    "    validation_datagen = ImageDataGenerator()\n",
    "\n",
    "    training_generator = training_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        target_size=(w, h),\n",
    "        # color_mode='grayscale',\n",
    "        batch_size=batch_size\n",
    "\n",
    "    )\n",
    "\n",
    "    validation_generator = validation_datagen.flow_from_directory(\n",
    "        val_path,\n",
    "        target_size=(w, h),\n",
    "        # color_mode='grayscale',\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    return training_generator, validation_generator\n",
    "\n",
    "def load_data(root, split, input_shape, classes):\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    print('Read train images')\n",
    "\n",
    "#     classes = glob.glob(root+'*')\n",
    "#     print(classes)\n",
    "\n",
    "    for j in range(0, len(classes)):\n",
    "        print('Load folder {}'.format(j))\n",
    "\n",
    "        files = glob.glob(root+classes[j]+'/*')\n",
    "        print(len(files))\n",
    "\n",
    "        # val_images = math.floor( len(files) * split )\n",
    "\n",
    "        # for i in range(0, val_images):\n",
    "\n",
    "        #     rand_idx = random.randint(0, len(files)-1)\n",
    "\n",
    "        #     fl = files[rand_idx]\n",
    "\n",
    "        #    files.pop(rand_idx)\n",
    "\n",
    "        #    img = get_im(fl, input_shape)\n",
    "        #    X_val.append(img)\n",
    "        #    y_val.append(j)\n",
    "\n",
    "        for fl in files:\n",
    "            img = get_im(fl, input_shape)\n",
    "            X_train.append(img)\n",
    "            y_train.append(j)\n",
    "\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = split_validation_set(np.array(X_train), np.array(y_train), split)\n",
    "\n",
    "    print(\"Using {} imgs for training and {} imgs for validation\".format( len(X_train), len(X_val) ) )\n",
    "\n",
    "    return X_train, y_train, X_val, y_val\n",
    "\n",
    "def get_im(path, input_shape):\n",
    "    # Load as grayscale\n",
    "    # print(path)\n",
    "    try:\n",
    "        img = cv2.imread(path)\n",
    "\n",
    "        # Reduce size\n",
    "        resized = cv2.resize(img, (input_shape[0], input_shape[1]) )\n",
    "        if(input_shape[2] == 1):\n",
    "            resized = cv2.cvtColor(resized, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        resized = ((resized/255.0) - 0.5)*2.0\n",
    "    except:\n",
    "        print(\"something is off with {}\".format(path))\n",
    "        return\n",
    "\n",
    "\n",
    "    return resized\n",
    "\n",
    "def split_validation_set(train, labels, test_size):\n",
    "    random_state = 51\n",
    "    X_train, X_test, y_train, y_test = train_test_split(train, labels, test_size=test_size, random_state=random_state)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# parameters\n",
    "batch_size = 32# * 4\n",
    "num_epochs = 10000\n",
    "\n",
    "conv2d_filters = [2, 4, 8, 12, 16, 32]\n",
    "# input_shapes = [(32, 32, 3), (48, 48, 3), (64, 64, 3), (80, 80, 3)]\n",
    "input_shape = (64, 64, 3)\n",
    "residual_layers = range(1,10)\n",
    "conv_layers = range(1,10)\n",
    "\n",
    "validation_split = .2\n",
    "verbose = 1\n",
    "num_classes = 4\n",
    "patience = 50\n",
    "gestures = ['nohand','peace','stop','thumbsup']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read train images\n",
      "Load folder 0\n",
      "11350\n",
      "Load folder 1\n",
      "18633\n",
      "Load folder 2\n",
      "9540\n",
      "Load folder 3\n",
      "19788\n",
      "Using 47448 imgs for training and 11863 imgs for validation\n",
      "Read train images\n",
      "Load folder 0\n",
      "1500\n",
      "Load folder 1\n",
      "1500\n",
      "Load folder 2\n",
      "1000\n",
      "Load folder 3\n",
      "1500\n",
      "Using 5500 imgs for training and 0 imgs for validation\n"
     ]
    }
   ],
   "source": [
    "root = '/Users/jmarcano/dev/withme/HandGesturesAndTracking/images/CommonHandGestures/training_data/'\n",
    "\n",
    "root_test = '/Users/jmarcano/dev/withme/HandGesturesAndTracking/images/CommonHandGestures/testing_data/'\n",
    "x_train, y_train, x_val, y_val = load_data(root, 0.2, input_shape, gestures )\n",
    "\n",
    "x_test, y_test, dummy1, dummy2 = load_data(root_test, 0.0, input_shape, gestures)\n",
    "\n",
    "# fdata = open('train_val_data_{}_{}_{}.pickle'.format(input_shape[0], input_shape[1], input_shape[2]), 'wb')\n",
    "\n",
    "# pickle.dump([x_train, y_train, x_val, y_val], fdata)\n",
    "\n",
    "# fdata.close()\n",
    "\n",
    "# fdata2 = open('test_{}_{}_{}.pickle'.format(input_shape[0], input_shape[1], input_shape[2]), 'wb')\n",
    "\n",
    "\n",
    "# pickle.dump([x_test, y_test], fdata2)\n",
    "\n",
    "# fdata2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10\n",
      "a\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Initializer for variable conv2d_247/kernel/ is from inside a control-flow construct, such as a loop or conditional. When creating a variable inside a loop or conditional, use a lambda as the initializer.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-4f3bc0e57b4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m                                                                      conv_layer, residual_layer)\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResidualNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresidual_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv2d_filters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconv2d_filter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             model.compile(optimizer='adam', loss='categorical_crossentropy',\n\u001b[1;32m     24\u001b[0m                           metrics=['accuracy'])\n",
      "\u001b[0;32m~/dev/withme/emotion/keras/GenericNetworkBuilder.py\u001b[0m in \u001b[0;36mResidualNet\u001b[0;34m(input_shape, num_classes, residual_layers, conv_layers, l2_regularization, init_strides, residual_strides, conv2d_filters, pooling_strides)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     x = Conv2D( conv2d_filters // 2, (3, 3), strides=init_strides, kernel_regularizer=regularization,\n\u001b[0;32m---> 22\u001b[0;31m                use_bias=False)(img_input)\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mActivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    429\u001b[0m                                          \u001b[0;34m'You can build it manually via: '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m                                          '`layer.build(batch_input_shape)`')\n\u001b[0;32m--> 431\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    136\u001b[0m                                       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'kernel'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                                       \u001b[0mregularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_regularizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                                       constraint=self.kernel_constraint)\n\u001b[0m\u001b[1;32m    139\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             self.bias = self.add_weight(shape=(self.filters,),\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36madd_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint)\u001b[0m\n\u001b[1;32m    250\u001b[0m                             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m                             \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m                             constraint=constraint)\n\u001b[0m\u001b[1;32m    253\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mregularizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'weight_regularizer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mvariable\u001b[0;34m(value, dtype, name, constraint)\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uses_learning_phase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m     \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint)\u001b[0m\n\u001b[1;32m    233\u001b[0m           \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m           \u001b[0mexpected_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexpected_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m           constraint=constraint)\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m_init_from_args\u001b[0;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, expected_shape, constraint)\u001b[0m\n\u001b[1;32m    360\u001b[0m                 \u001b[0;34m\"construct, such as a loop or conditional. When creating a \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0;34m\"variable inside a loop or conditional, use a lambda as the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m                 \"initializer.\" % name)\n\u001b[0m\u001b[1;32m    363\u001b[0m           \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m           shape = (self._initial_value.get_shape()\n",
      "\u001b[0;31mValueError\u001b[0m: Initializer for variable conv2d_247/kernel/ is from inside a control-flow construct, such as a loop or conditional. When creating a variable inside a loop or conditional, use a lambda as the initializer."
     ]
    }
   ],
   "source": [
    "residual_layers = range(10,1,-1)\n",
    "conv_layers = range(10,1,-1)\n",
    "conv2d_filters = [16, 12, 8, 4]\n",
    "for conv_layer in conv_layers:\n",
    "\n",
    "    for residual_layer in residual_layers:\n",
    "        \n",
    "        print(conv_layer, residual_layer)\n",
    "\n",
    "        for conv2d_filter in conv2d_filters:\n",
    "            print(\"a\")\n",
    "            now = datetime.datetime.now()\n",
    "            base_path = 'arch_eval2/'\n",
    "            base_path += now.strftime(\"%Y_%m_%d_%H_%M_%S\")+'/'\n",
    "            if not os.path.exists(base_path):\n",
    "                os.makedirs(base_path)\n",
    "            # datasets_path = 'data/fer2013/fer2013.csv'\n",
    "            model_name = \"ResidualNet_{}x{}x{}_conv_{}_res{}\".format(input_shape[0], input_shape[1], input_shape[2],\n",
    "                                                                     conv_layer, residual_layer)\n",
    "\n",
    "            model = ResidualNet(input_shape, num_classes, residual_layer, conv_layer, conv2d_filters=conv2d_filter)\n",
    "            model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
    "                          metrics=['accuracy'])\n",
    "            model.summary()\n",
    "\n",
    "            # begin training\n",
    "            log_file_path = base_path + model_name+'_training.log'\n",
    "            csv_logger = CSVLogger(log_file_path, append=False)\n",
    "            early_stop = EarlyStopping('val_loss', patience=patience)\n",
    "            reduce_lr = ReduceLROnPlateau('val_loss', factor=0.1,\n",
    "                                          patience=int(patience/4), verbose=1)\n",
    "            trained_models_path = base_path + model_name\n",
    "            model_names = trained_models_path + '.{epoch:02d}-{val_acc:.2f}.hdf5'\n",
    "            # model_checkpoint = ModelCheckpoint(model_names, 'val_loss', verbose=1, save_best_only=True)\n",
    "\n",
    "            model_checkpoint = ModelCheckpointConfusion(model_names, 'val_acc', verbose=1,\n",
    "                                            save_best_only=True, gestures=gestures, test_split= (x_test, y_test) )\n",
    "\n",
    "            callbacks = [model_checkpoint, csv_logger, early_stop, reduce_lr]\n",
    "\n",
    "            try:\n",
    "                history = model.fit(x=x_train,\n",
    "                                    y=y_train,\n",
    "                                    batch_size=batch_size,\n",
    "                                    epochs=2, verbose=1, callbacks=callbacks,\n",
    "                                    validation_data=(x_val, y_val),\n",
    "                                    steps_per_epoch=len(x_train) // batch_size,\n",
    "                                    validation_steps=len(x_val) // batch_size\n",
    "                                    )\n",
    "\n",
    "                # history = model.fit_generator(\n",
    "                #      generator=training_generator,\n",
    "                #      steps_per_epoch=60000 // batch_size,  # // batch_size,\n",
    "                #      epochs=num_epochs,\n",
    "                #      verbose=1, callbacks=callbacks,\n",
    "                #      validation_data=validation_generator,\n",
    "                #      validation_steps=100,  # // batch_size,\n",
    "                #      workers=8,\n",
    "                #  )\n",
    "\n",
    "\n",
    "                # pickle.dump(history, open(base_path + model_name + '_history.pickle', 'wb'))\n",
    "\n",
    "            except:\n",
    "                \n",
    "                print(\"-\"*80)\n",
    "                print(\"Failed with params: input_shape {} , conv layers {} , residual layers {} , and conv filters {}\".format(\n",
    "                    input_shape, conv_layer, residual_layer, conv2d_filters\n",
    "                ))\n",
    "                \n",
    "                history = model.fit(x=x_train,\n",
    "                                    y=y_train,\n",
    "                                    batch_size=batch_size,\n",
    "                                    epochs=2, verbose=1, callbacks=callbacks,\n",
    "                                    validation_data=(x_val, y_val),\n",
    "                                    steps_per_epoch=len(x_train) // batch_size,\n",
    "                                    validation_steps=len(x_val) // batch_size\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 64, 64, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 62, 62, 4)    108         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 62, 62, 4)    16          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 62, 62, 4)    0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 60, 60, 4)    144         activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 60, 60, 4)    16          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 60, 60, 4)    0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 58, 58, 4)    144         activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 58, 58, 4)    16          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 58, 58, 4)    0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 56, 56, 4)    144         activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 56, 56, 4)    16          conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 56, 56, 4)    0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 54, 54, 4)    144         activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 54, 54, 4)    16          conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 54, 54, 4)    0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 52, 52, 4)    144         activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 52, 52, 4)    16          conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 52, 52, 4)    0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 50, 50, 4)    144         activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 50, 50, 4)    16          conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 50, 50, 4)    0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_1 (SeparableCo (None, 50, 50, 8)    68          activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 50, 50, 8)    32          separable_conv2d_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 50, 50, 8)    0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2 (SeparableCo (None, 50, 50, 8)    136         activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 50, 50, 8)    32          separable_conv2d_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 25, 25, 8)    32          activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 25, 25, 8)    0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 25, 25, 8)    32          conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 25, 25, 8)    0           max_pooling2d_1[0][0]            \n",
      "                                                                 batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_3 (SeparableCo (None, 25, 25, 16)   200         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 25, 25, 16)   64          separable_conv2d_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 25, 25, 16)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_4 (SeparableCo (None, 25, 25, 16)   400         activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 25, 25, 16)   64          separable_conv2d_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 13, 13, 16)   128         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 16)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 13, 13, 16)   64          conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 13, 13, 16)   0           max_pooling2d_2[0][0]            \n",
      "                                                                 batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_5 (SeparableCo (None, 13, 13, 24)   528         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 13, 13, 24)   96          separable_conv2d_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 13, 13, 24)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_6 (SeparableCo (None, 13, 13, 24)   792         activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 13, 13, 24)   96          separable_conv2d_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 7, 7, 24)     384         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 7, 7, 24)     0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 7, 7, 24)     96          conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 7, 7, 24)     0           max_pooling2d_3[0][0]            \n",
      "                                                                 batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_7 (SeparableCo (None, 7, 7, 32)     984         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 7, 7, 32)     128         separable_conv2d_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 7, 7, 32)     0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_8 (SeparableCo (None, 7, 7, 32)     1312        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 7, 7, 32)     128         separable_conv2d_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 4, 4, 32)     768         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 4, 4, 32)     0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 4, 4, 32)     128         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 4, 4, 32)     0           max_pooling2d_4[0][0]            \n",
      "                                                                 batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_9 (SeparableCo (None, 4, 4, 40)     1568        add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 4, 4, 40)     160         separable_conv2d_9[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 4, 4, 40)     0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_10 (SeparableC (None, 4, 4, 40)     1960        activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 4, 4, 40)     160         separable_conv2d_10[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 2, 2, 40)     1280        add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 2, 2, 40)     0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 2, 2, 40)     160         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 2, 2, 40)     0           max_pooling2d_5[0][0]            \n",
      "                                                                 batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_11 (SeparableC (None, 2, 2, 48)     2280        add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 2, 2, 48)     192         separable_conv2d_11[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 2, 2, 48)     0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_12 (SeparableC (None, 2, 2, 48)     2736        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 2, 2, 48)     192         separable_conv2d_12[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 1, 1, 48)     1920        add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 1, 1, 48)     0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 1, 1, 48)     192         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 1, 1, 48)     0           max_pooling2d_6[0][0]            \n",
      "                                                                 batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 1, 1, 4)      1732        add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 4)            0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Activation)        (None, 4)            0           global_average_pooling2d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 22,308\n",
      "Trainable params: 21,244\n",
      "Non-trainable params: 1,064\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_layer =6\n",
    "residual_layer=6\n",
    "conv2d_filter=8\n",
    "print(\"a\")\n",
    "now = datetime.datetime.now()\n",
    "base_path = 'arch_eval2/'\n",
    "base_path += now.strftime(\"%Y_%m_%d_%H_%M_%S\")+'/'\n",
    "if not os.path.exists(base_path):\n",
    "    os.makedirs(base_path)\n",
    "# datasets_path = 'data/fer2013/fer2013.csv'\n",
    "model_name = \"ResidualNet_{}x{}x{}_conv_{}_res{}\".format(input_shape[0], input_shape[1], input_shape[2],\n",
    "                                                         6, 6)\n",
    "\n",
    "model = ResidualNet(input_shape, num_classes, residual_layer, conv_layer, conv2d_filters=conv2d_filter)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# begin training\n",
    "log_file_path = base_path + model_name+'_training.log'\n",
    "csv_logger = CSVLogger(log_file_path, append=False)\n",
    "early_stop = EarlyStopping('val_loss', patience=patience)\n",
    "reduce_lr = ReduceLROnPlateau('val_loss', factor=0.1,\n",
    "                              patience=int(patience/4), verbose=1)\n",
    "trained_models_path = base_path + model_name\n",
    "model_names = trained_models_path + '.{epoch:02d}-{val_acc:.2f}.hdf5'\n",
    "# model_checkpoint = ModelCheckpoint(model_names, 'val_loss', verbose=1, save_best_only=True)\n",
    "\n",
    "model_checkpoint = ModelCheckpointConfusion(model_names, 'val_acc', verbose=1,\n",
    "                                save_best_only=True, gestures=gestures, test_split= (x_test, y_test) )\n",
    "\n",
    "callbacks = [model_checkpoint, csv_logger, early_stop, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x=x_train,\n",
    "                                    y=y_train,\n",
    "                                    batch_size=batch_size,\n",
    "                                    epochs=2, verbose=1,\n",
    "                                    validation_data=(x_val, y_val),\n",
    "                                    steps_per_epoch=len(x_train) // batch_size,\n",
    "                                    validation_steps=len(x_val) // batch_size\n",
    "                                    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
