{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### read raw images and landmarks\n",
    "\n",
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "muct_data_path = '/Users/azhong/face/clmtools/pdm_builder/data/images/'\n",
    "muct_annotation_path = '/Users/azhong/face/clmtools/pdm_builder/data/annotations.csv'\n",
    "\n",
    "landmark_dict = {}\n",
    "raw_image_dict = {}\n",
    "image_dict = {}\n",
    "mouth_dict = {}\n",
    "mouth_openness_absolute = {}\n",
    "image_array = []\n",
    "landmarks_array = []\n",
    "image_dim_dict = {}\n",
    "mouth_landmarks = range(44, 62)\n",
    "\n",
    "with open(muct_annotation_path) as fi:\n",
    "    for line in fi:\n",
    "        splitted = line.split(';')\n",
    "        filename = os.path.join(muct_data_path, splitted[0])\n",
    "        if os.path.isfile(filename):\n",
    "            landmark_dict[splitted[0]] = [[float(splitted[i*3+1]), float(splitted[i*3+2])] for i in range(71)]\n",
    "            landmark_dict[splitted[0]] = np.array(landmark_dict[splitted[0]])\n",
    "            raw_image_dict[splitted[0]] = cv2.cvtColor(cv2.imread(filename), cv2.COLOR_BGR2GRAY)\n",
    "            image_dim_dict[splitted[0]] = raw_image_dict[splitted[0]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### augment images (randomly rotate/scale/translate)\n",
    "\n",
    "import random\n",
    "import math\n",
    "augment_count = 5\n",
    "random.seed()\n",
    "for i in sorted(landmark_dict.keys()):\n",
    "    x2, y2 = np.amax(landmark_dict[i], axis=0)\n",
    "    x1, y1 = np.amin(landmark_dict[i], axis=0)\n",
    "    x1 = int(x1)\n",
    "    x2 = int(x2)\n",
    "    # extend up further to forehead\n",
    "    y1 = max(int(y1 - (y2-y1)*0.2), 0)\n",
    "    y2 = int(y2)\n",
    "    \n",
    "    mouth_left_x, mouth_left_y = landmark_dict[i][44]\n",
    "    mouth_right_x, mouth_right_y = landmark_dict[i][50]\n",
    "    \n",
    "    for j in range(augment_count):\n",
    "        x11 = x1\n",
    "        y11 = y1\n",
    "        x22 = x2\n",
    "        y22 = y2\n",
    "\n",
    "        if y22 - y11 > x22 - x11:\n",
    "            diff = (y22 - y11 - (x22 - x11))/2.0\n",
    "            x111 = max(int(x11-diff), 0)\n",
    "            x222 = min(int(x22+diff), image_dim_dict[i][1])\n",
    "            y111 = int(y11)\n",
    "            y222 = int(y22)\n",
    "        else:\n",
    "            diff = (x22 - x11 - (y22 - y11))/2.0\n",
    "            y111 = max(int(y11-diff), 0)\n",
    "            y222 = min(int(y22+diff), image_dim_dict[i][0])\n",
    "            x111 = int(x11)\n",
    "            x222 = int(x22)\n",
    "\n",
    "        # randomly rotate image by -10 to 10 degrees\n",
    "        angle = (random.random()*2-1)*10\n",
    "        # randomly scale image 0.9-1.1\n",
    "        ratio = (random.random()*2-1)*0.1 + 1\n",
    "        translate_x = int(np.round((random.random()*2-1) * 0.10 * 32))\n",
    "        translate_y = int(np.round((random.random()*2-1) * 0.10 * 16))\n",
    "\n",
    "        mouth_center = ((mouth_left_x+mouth_right_x)/2.0, \n",
    "                        (mouth_left_y+mouth_right_y)/2.0)\n",
    "        M = cv2.getRotationMatrix2D(((mouth_left_x+mouth_right_x)/2, \n",
    "                                     (mouth_left_y+mouth_right_y)/2), angle, ratio)\n",
    "        rotated_image = cv2.warpAffine(raw_image_dict[i], M, (image_dim_dict[i][1], image_dim_dict[i][0]))\n",
    "#         print('angle ', angle, 'ratio', ratio, 'x', translate_x, 'y', translate_y)\n",
    "#         plt.imshow(raw_image_dict[i], cmap='gray')\n",
    "#         plt.show()\n",
    "#         plt.imshow(rotated_image, cmap='gray')\n",
    "#         plt.show()\n",
    "\n",
    "        mod_image_resized = cv2.resize(rotated_image[y111:y222, x111:x222], (64, 64))\n",
    "        mouth_center_resized = ((mouth_center[0]-x111)/(x222-x111)*64, (mouth_center[1]-y111)/(y222-y111)*64)\n",
    "        center_x, center_y = (int(mouth_center_resized[0]), int(mouth_center_resized[1]))\n",
    "##        cv2.circle(mod_image_resized, (int(mouth_center_resized[0]), int(mouth_center_resized[1])), 2, (255))\n",
    "#         plt.imshow(mod_image_resized, cmap='gray')\n",
    "#         plt.show()\n",
    "        image_dict[i + '_augment_' + str(j*2)] = mod_image_resized\n",
    "        image_dict[i + '_augment_' + str(j*2+1)] =  np.fliplr(mod_image_resized)\n",
    "\n",
    "        blank = mod_image_resized.copy()\n",
    "        blank.fill(127.5)\n",
    "        \n",
    "        for ii in range(max(0, center_x-16), min(center_x+16, 63)):\n",
    "            for jj in range(max(0, center_y-8), min(center_y+8, 63)):\n",
    "                blank[jj - max(center_y-8, 0) + 40][ii-max(0, center_x-16)+16] = mod_image_resized[jj+translate_y][ii+translate_x]\n",
    "\n",
    "        mouth_dict[i + '_augment_' + str(j*2)] = blank\n",
    "        mouth_dict[i + '_augment_' + str(j*2+1)] = np.fliplr(blank)\n",
    "        \n",
    "        mouth_openness_absolute_x = (landmark_dict[i][57][0] - landmark_dict[i][60][0]) / (x222-x111) * 64 * ratio\n",
    "        mouth_openness_absolute_y = (landmark_dict[i][57][1] - landmark_dict[i][60][1]) / (y222-y111) * 64 * ratio\n",
    "        mouth_openness_absolute[i + '_augment_' + str(j*2)] = np.linalg.norm(np.array([mouth_openness_absolute_x, mouth_openness_absolute_y]))\n",
    "        mouth_openness_absolute[i + '_augment_' + str(j*2+1)] = np.linalg.norm(np.array([mouth_openness_absolute_x, mouth_openness_absolute_y]))\n",
    "        \n",
    "#         plt.imshow(blank, cmap = 'gray')\n",
    "#         plt.show()\n",
    "#         plt.imshow(np.fliplr(blank), cmap = 'gray')\n",
    "#         plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mouth_openness_top_down = {}\n",
    "mouth_openness_left_right = {}\n",
    "\n",
    "for i in sorted(landmark_dict.keys()):\n",
    "    left_right = np.linalg.norm(landmark_dict[i][44] - landmark_dict[i][50])                  \n",
    "    top_down   = np.linalg.norm(landmark_dict[i][47] - landmark_dict[i][53])\n",
    "    openness   = np.linalg.norm(landmark_dict[i][57] - landmark_dict[i][60])\n",
    "    if openness/left_right >= 0.1:\n",
    "        mouth_openness_left_right[i] = openness/left_right\n",
    "    else:\n",
    "        mouth_openness_left_right[i] = 0\n",
    "    if openness/top_down >= 0.1: \n",
    "        mouth_openness_top_down[i]   = openness/top_down\n",
    "    else:\n",
    "        mouth_openness_top_down[i]   = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "emotion_model_path = '../tensorflow/models/emotion_mini_XCEPTION_64x64_0.66_7ms.hdf5.pb'\n",
    "graph = tf.Graph()\n",
    "graph_def = tf.GraphDef()\n",
    "with open(emotion_model_path, \"rb\") as f:\n",
    "    graph_def.ParseFromString(f.read())\n",
    "with graph.as_default():\n",
    "    tf.import_graph_def(graph_def)\n",
    "input_name = 'import/input_1'\n",
    "output_add_name = 'import/add_4/add'\n",
    "output_conv_name = 'import/conv2d_7/BiasAdd'\n",
    "output_name = 'import/output_node0'\n",
    "\n",
    "input_operation = graph.get_operation_by_name(input_name)\n",
    "output_add_operation  = graph.get_operation_by_name(output_add_name)\n",
    "output_conv_operation = graph.get_operation_by_name(output_conv_name)\n",
    "output_operation = graph.get_operation_by_name(output_name)\n",
    "\n",
    "input_shape = (int(input_operation.outputs[0].shape.dims[1]),\n",
    "               int(input_operation.outputs[0].shape.dims[2]),\n",
    "               1)\n",
    "\n",
    "add_dict = {}\n",
    "mean_of_add_dict = {}\n",
    "conv_dict = {}\n",
    "output_dict = {}\n",
    "add_sampled_dict = {}\n",
    "sess = tf.Session(graph = graph)\n",
    "for i in sorted(mouth_dict.keys()):\n",
    "    gray_face = (mouth_dict[i] - 127.5) / 127.5\n",
    "    gray_face = np.expand_dims(gray_face, 0)\n",
    "    gray_face = np.expand_dims(gray_face, -1)\n",
    "    prediction = sess.run([output_add_operation.outputs[0], output_conv_operation.outputs[0], output_operation.outputs[0]],\n",
    "                          {input_operation.outputs[0]: gray_face})\n",
    "    add_out = prediction[0][0]\n",
    "    add_out = add_out.reshape(16, 128)\n",
    "    mean_of_add_out = np.mean(add_out, axis=0)\n",
    "    add_out = add_out.reshape(2048)\n",
    "    add_dict[i] = add_out.copy()\n",
    "    add_sampled_dict[i] = [add_out[j] for j in [728, 1749, 1741, 1914]]\n",
    "    mean_of_add_dict[i] = mean_of_add_out.copy()\n",
    "    conv_dict[i] = prediction[1][0].reshape(112)\n",
    "    output_dict[i] = prediction[2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total size is 5110\n",
      "top down mouth open ratio\n",
      "[-0.08985995 -0.09510303 -0.09228775]\n",
      "left right mouth open ratio\n",
      "[-0.05188474 -0.07319056 -0.05202475]\n",
      "absolute mouth openness in pixels\n",
      "[-0.84608506 -0.89872536 -0.84876263]\n",
      "0.8371961157268301\n",
      "0.9282827687367852\n",
      "0.908077069344158\n"
     ]
    }
   ],
   "source": [
    "# preparing SVM\n",
    "\n",
    "X = []\n",
    "y_left_right = []\n",
    "y_top_down = []\n",
    "y_absolute = []\n",
    "\n",
    "sorted_keys = sorted(mouth_dict.keys())\n",
    "np.random.shuffle(sorted_keys)\n",
    "# shuffle\n",
    "for i in sorted_keys:\n",
    "    X.append(list(add_dict[i]))\n",
    "    filename = i.split('_augment_')[0]\n",
    "    y_left_right.append(mouth_openness_left_right[filename])\n",
    "    y_top_down.append(mouth_openness_top_down[filename])\n",
    "    y_absolute.append(mouth_openness_absolute[i])\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "clf_0 = svm.LinearSVR()\n",
    "clf_1 = svm.LinearSVR()\n",
    "clf_2 = svm.LinearSVR()\n",
    "\n",
    "total_size = len(X)\n",
    "print('total size is {}'.format(total_size))\n",
    "train_size = int(0.8*total_size)\n",
    "\n",
    "print('top down mouth open ratio')\n",
    "print(cross_val_score(clf_0, X, y_top_down, scoring='neg_mean_absolute_error'))\n",
    "\n",
    "print('left right mouth open ratio')\n",
    "print(cross_val_score(clf_1, X, y_left_right, scoring='neg_mean_absolute_error'))\n",
    "\n",
    "print('absolute mouth openness in pixels')\n",
    "print(cross_val_score(clf_2, X, y_absolute, scoring='neg_mean_absolute_error'))\n",
    "\n",
    "\n",
    "#cross_val_score(clf, X, y, scoring='neg_mean_absolute_error') \n",
    "clf_0.fit(X, y_top_down)\n",
    "clf_1.fit(X, y_left_right)\n",
    "clf_2.fit(X, y_absolute)\n",
    "\n",
    "print(clf_0.score(X, y_top_down))\n",
    "print(clf_1.score(X, y_left_right))\n",
    "print(clf_2.score(X, y_absolute))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mouth_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-30545bdea226>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcounter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmouth_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mcounter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdebug_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmouth_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_augment_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mouth_dict' is not defined"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for i in sorted(mouth_dict.keys()):\n",
    "    counter += 1\n",
    "    debug_img = mouth_dict[i].copy()\n",
    "    filename = i.split('_augment_')[0]\n",
    "    plt.imshow(debug_img, cmap='gray')\n",
    "    plt.title('mouth openness top-down {:01.2f} - predicted {:01.2f}; '\\\n",
    "    'left-right {:01.2f} - predicted {:01.2f} '\\\n",
    "    'absolute {:01.1f} - predicted {:01.1f}'.format(\n",
    "        mouth_openness_top_down[filename], \n",
    "        clf_0.predict([list(add_dict[i])])[0],\n",
    "        mouth_openness_left_right[filename],\n",
    "        clf_1.predict([list(add_dict[i])])[0],\n",
    "        mouth_openness_absolute[i],\n",
    "        clf_2.predict([list(add_dict[i])])[0],\n",
    "    ))\n",
    "#     plt.show()\n",
    "    if counter > 100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(list(clf_0.coef_))\n",
    "# print(list(clf_0.intercept_))\n",
    "# print(list(clf_1.coef_))\n",
    "# print(list(clf_1.intercept_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(list(clf_2.coef_))\n",
    "# print(list(clf_2.intercept_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
